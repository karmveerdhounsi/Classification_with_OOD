{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":15444,"sourceType":"datasetVersion","datasetId":11102},{"sourceId":12744920,"sourceType":"datasetVersion","datasetId":8056640}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# =================================================================\n# Cell 1: Setup, Imports, and Configuration\n# =================================================================\nimport os\nimport time\nimport json\nimport pickle\nimport random\nfrom collections import defaultdict\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import Dataset, DataLoader, random_split, Subset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50, ResNet50_Weights\n\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n# -----------------------\n# CONFIGURATION\n# -----------------------\nclass Config:\n    # --- Paths ---\n    AWA2_DIR = \"/kaggle/input/awa2-data/Animals_with_Attributes2\"\n    OOD_DIR = \"/kaggle/input/cifar10-python/cifar-10-batches-py\"\n    OUTPUT_DIR = \"/kaggle/working/\"\n    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n    # --- Data & Model ---\n    IMAGE_SIZE = 224\n    BATCH_SIZE = 64\n    NUM_WORKERS = 2\n    NUM_AWA2_CLASSES = 50\n    \n    # [FAIR EVAL] New 3-way data split ratios for AWA2\n    AWA2_TRAIN_RATIO = 0.7 # 70% for training\n    AWA2_VAL_RATIO = 0.1   # 10% for validation\n    # The remaining 20% will be for testing\n\n    # [FAIR EVAL] Define sizes for OOD validation and test sets\n    NUM_OOD_VAL_IMAGES = 2000\n    NUM_OOD_TEST_IMAGES = 10000\n\n    # --- Training ---\n    EPOCHS = 10\n    LEARNING_RATE = 1e-4\n    WEIGHT_DECAY = 1e-4\n\n    # --- NCI Evaluation ---\n    NCI_ALPHA = 1e-3 # Filtering strength for the L1 norm component\n\ncfg = Config()\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\nprint(\"Config:\", {k: v for k, v in cfg.__dict__.items() if not k.startswith('__')})\ncudnn.benchmark = True\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T11:38:39.407542Z","iopub.execute_input":"2025-08-14T11:38:39.408028Z","iopub.status.idle":"2025-08-14T11:38:47.289074Z","shell.execute_reply.started":"2025-08-14T11:38:39.408005Z","shell.execute_reply":"2025-08-14T11:38:47.288269Z"}},"outputs":[{"name":"stdout","text":"Config: {}\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# =================================================================\n# Cell 2: Data Loading and 3-Way Split (Train/Val/Test)\n# =================================================================\n\ndata_tfms = transforms.Compose([\n    transforms.Resize((cfg.IMAGE_SIZE, cfg.IMAGE_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\nclass ImagePathDataset(Dataset):\n    def __init__(self, paths, labels, transform):\n        self.paths, self.labels, self.transform = paths, labels, transform\n    def __len__(self): return len(self.paths)\n    def __getitem__(self, idx):\n        p, y = self.paths[idx], self.labels[idx]\n        try: img = Image.open(p).convert(\"RGB\")\n        except: img = Image.new(\"RGB\", (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE))\n        return self.transform(img), y\n\nclass ImageObjectDataset(Dataset):\n    def __init__(self, images, labels, transform):\n        self.images, self.labels, self.transform = images, labels, transform\n    def __len__(self): return len(self.images)\n    def __getitem__(self, idx):\n        return self.transform(self.images[idx]), self.labels[idx]\n\n# --- 1. Load AWA2 Data and perform a 3-way split ---\nprint(\"\\nLoading and splitting AWA2 data...\")\ndf_classes = pd.read_csv(os.path.join(cfg.AWA2_DIR, 'classes.txt'), sep='\\t', header=None, names=['id', 'class_name'])\nid_to_class_name = {i: row['class_name'] for i, row in df_classes.iterrows()}\nimg_root = os.path.join(cfg.AWA2_DIR, \"JPEGImages\")\nall_paths, all_labels = [], []\nfor cid, class_name in sorted(id_to_class_name.items(), key=lambda x: x[0]):\n    folder = os.path.join(img_root, class_name)\n    if not os.path.isdir(folder): continue\n    for fname in os.listdir(folder):\n        if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n            all_paths.append(os.path.join(folder, fname))\n            all_labels.append(cid)\n\nfull_dataset = ImagePathDataset(all_paths, all_labels, transform=data_tfms)\n\n# Calculate split sizes\ntrain_size = int(cfg.AWA2_TRAIN_RATIO * len(full_dataset))\nval_size = int(cfg.AWA2_VAL_RATIO * len(full_dataset))\ntest_size = len(full_dataset) - train_size - val_size\n\n# Split the dataset\ntrain_ds, val_ds_awa2, test_ds_awa2 = random_split(\n    full_dataset, [train_size, val_size, test_size],\n    generator=torch.Generator().manual_seed(42)\n)\nprint(f\"AWA2 data split: {len(train_ds)} training, {len(val_ds_awa2)} validation, {len(test_ds_awa2)} testing.\")\n\n# --- 2. Load and split CIFAR-10 OOD Data ---\ndef unpickle(file):\n    with open(file, 'rb') as fo: return pickle.load(fo, encoding='bytes')\nall_ood_images = []\nnon_animal_labels = {0, 1, 8, 9} # airplane, automobile, ship, truck\nfor i in range(1, 6):\n    p = os.path.join(cfg.OOD_DIR, f\"data_batch_{i}\")\n    if not os.path.exists(p): continue\n    d = unpickle(p)\n    for j, label in enumerate(d[b'labels']):\n        if label in non_animal_labels:\n            all_ood_images.append(Image.fromarray(d[b'data'][j].reshape(3, 32, 32).transpose(1, 2, 0)))\nrandom.seed(42); random.shuffle(all_ood_images)\n\n# Create separate OOD sets for validation and testing\nval_ood_images = all_ood_images[:cfg.NUM_OOD_VAL_IMAGES]\ntest_ood_images = all_ood_images[cfg.NUM_OOD_VAL_IMAGES : cfg.NUM_OOD_VAL_IMAGES + cfg.NUM_OOD_TEST_IMAGES]\n\nval_ds_ood = ImageObjectDataset(val_ood_images, [-1]*len(val_ood_images), data_tfms)\ntest_ds_ood = ImageObjectDataset(test_ood_images, [-1]*len(test_ood_images), data_tfms)\nprint(f\"CIFAR-10 OOD data split: {len(val_ds_ood)} validation, {len(test_ds_ood)} testing.\")\n\n# --- 3. Create Final Dataloaders ---\ntrain_loader = DataLoader(train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True, num_workers=cfg.NUM_WORKERS)\n\n# Validation loader (mixed AWA2 val + OOD val)\nval_loader = DataLoader(\n    torch.utils.data.ConcatDataset([val_ds_awa2, val_ds_ood]),\n    batch_size=cfg.BATCH_SIZE, shuffle=False, num_workers=cfg.NUM_WORKERS\n)\n\n# Test loader (mixed AWA2 test + OOD test)\ntest_loader = DataLoader(\n    torch.utils.data.ConcatDataset([test_ds_awa2, test_ds_ood]),\n    batch_size=cfg.BATCH_SIZE, shuffle=False, num_workers=cfg.NUM_WORKERS\n)\nprint(f\"Final loader sizes: Train={len(train_loader.dataset)}, Val={len(val_loader.dataset)}, Test={len(test_loader.dataset)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T11:38:53.039120Z","iopub.execute_input":"2025-08-14T11:38:53.040002Z","iopub.status.idle":"2025-08-14T11:38:56.191380Z","shell.execute_reply.started":"2025-08-14T11:38:53.039975Z","shell.execute_reply":"2025-08-14T11:38:56.190575Z"}},"outputs":[{"name":"stdout","text":"\nLoading and splitting AWA2 data...\nAWA2 data split: 26125 training, 3732 validation, 7465 testing.\nCIFAR-10 OOD data split: 2000 validation, 10000 testing.\nFinal loader sizes: Train=26125, Val=5732, Test=17465\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# =================================================================\n# Cell 3: Model Training\n# =================================================================\n\ndef train_classifier():\n    print(\"\\n--- Training AWA2 Classifier (Post-Hoc Method) ---\")\n    model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n    model.fc = nn.Linear(model.fc.in_features, cfg.NUM_AWA2_CLASSES)\n    model = model.to(cfg.DEVICE)\n    optimizer = optim.AdamW(model.parameters(), lr=cfg.LEARNING_RATE, weight_decay=cfg.WEIGHT_DECAY)\n    criterion = nn.CrossEntropyLoss()\n    \n    for epoch in range(1, cfg.EPOCHS + 1):\n        model.train()\n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{cfg.EPOCHS}\")\n        for x, y in pbar:\n            x, y = x.to(cfg.DEVICE), y.to(cfg.DEVICE)\n            optimizer.zero_grad()\n            loss = criterion(model(x), y)\n            loss.backward()\n            optimizer.step()\n            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n            \n    torch.save(model.state_dict(), os.path.join(cfg.OUTPUT_DIR, \"nci_classifier.pth\"))\n    print(\"Finished training and saved model.\")\n    return model\n\nmodel_path = os.path.join(cfg.OUTPUT_DIR, \"nci_classifier.pth\")\nif os.path.exists(model_path):\n    print(\"\\nFound existing classifier. Loading it.\")\n    model = resnet50(weights=None)\n    model.fc = nn.Linear(model.fc.in_features, cfg.NUM_AWA2_CLASSES)\n    model.load_state_dict(torch.load(model_path, map_location=cfg.DEVICE))\n    model.to(cfg.DEVICE)\nelse:\n    model = train_classifier()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T11:40:12.557143Z","iopub.execute_input":"2025-08-14T11:40:12.557507Z","iopub.status.idle":"2025-08-14T12:18:16.164550Z","shell.execute_reply.started":"2025-08-14T11:40:12.557473Z","shell.execute_reply":"2025-08-14T12:18:16.163757Z"}},"outputs":[{"name":"stdout","text":"\n--- Training AWA2 Classifier (Post-Hoc Method) ---\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10: 100%|██████████| 409/409 [05:28<00:00,  1.25it/s, loss=0.3067]\nEpoch 2/10: 100%|██████████| 409/409 [03:36<00:00,  1.89it/s, loss=0.0816]\nEpoch 3/10: 100%|██████████| 409/409 [03:38<00:00,  1.87it/s, loss=0.0161]\nEpoch 4/10: 100%|██████████| 409/409 [03:35<00:00,  1.90it/s, loss=0.2816]\nEpoch 5/10: 100%|██████████| 409/409 [03:36<00:00,  1.89it/s, loss=0.0379]\nEpoch 6/10: 100%|██████████| 409/409 [03:37<00:00,  1.88it/s, loss=0.0240]\nEpoch 7/10: 100%|██████████| 409/409 [03:38<00:00,  1.87it/s, loss=0.0217]\nEpoch 8/10: 100%|██████████| 409/409 [03:39<00:00,  1.87it/s, loss=0.0116]\nEpoch 9/10: 100%|██████████| 409/409 [03:36<00:00,  1.89it/s, loss=0.3028]\nEpoch 10/10: 100%|██████████| 409/409 [03:35<00:00,  1.89it/s, loss=0.0148]\n","output_type":"stream"},{"name":"stdout","text":"Finished training and saved model.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# =================================================================\n# Cell 4: NCI Setup (Post-Hoc Analysis)\n# =================================================================\n@torch.no_grad()\ndef setup_nci(model, train_loader):\n    print(\"\\n--- Setting up NCI detector (Post-Hoc Analysis) ---\")\n    model.eval()\n    feature_extractor = nn.Sequential(*list(model.children())[:-1])\n    \n    all_train_feats = []\n    # Use the train_loader which points to the correct training dataset\n    for x, y in tqdm(train_loader, desc=\"Extracting training features\"):\n        x = x.to(cfg.DEVICE)\n        feats = feature_extractor(x)\n        all_train_feats.append(torch.flatten(feats, 1))\n    all_train_feats = torch.cat(all_train_feats, dim=0)\n    \n    mu_G = all_train_feats.mean(dim=0)\n    print(f\"Calculated global feature mean (mu_G) from training data.\")\n    \n    w_c = model.fc.weight\n    print(f\"Extracted weight vectors (w_c) from trained model.\")\n    \n    return feature_extractor, mu_G, w_c\n\nfeature_extractor, mu_G, w_c = setup_nci(model, train_loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T12:21:05.829038Z","iopub.execute_input":"2025-08-14T12:21:05.829855Z","iopub.status.idle":"2025-08-14T12:24:14.797612Z","shell.execute_reply.started":"2025-08-14T12:21:05.829823Z","shell.execute_reply":"2025-08-14T12:24:14.796611Z"}},"outputs":[{"name":"stdout","text":"\n--- Setting up NCI detector (Post-Hoc Analysis) ---\n","output_type":"stream"},{"name":"stderr","text":"Extracting training features: 100%|██████████| 409/409 [03:08<00:00,  2.16it/s]","output_type":"stream"},{"name":"stdout","text":"Calculated global feature mean (mu_G) from training data.\nExtracted weight vectors (w_c) from trained model.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# =================================================================\n# Cell 5: Find Optimal Threshold using the VALIDATION Set\n# =================================================================\n@torch.no_grad()\ndef find_optimal_threshold(model, feature_extractor, mu_G, w_c, val_loader, alpha):\n    print(\"\\n--- Finding optimal threshold on validation set ---\")\n    model.eval()\n    feature_extractor.eval()\n    \n    all_nci_scores, all_true_labels = [], []\n    OOD_LABEL = -1\n    \n    for x, y_true in tqdm(val_loader, desc=\"Analyzing validation scores\"):\n        x = x.to(cfg.DEVICE)\n        logits = model(x)\n        h = torch.flatten(feature_extractor(x), 1)\n        predicted_classes = torch.argmax(logits, dim=1)\n        h_centered = h - mu_G\n        w_c_batch = w_c[predicted_classes]\n        \n        cos_sim = F.cosine_similarity(h_centered, w_c_batch)\n        w_c_norm = torch.norm(w_c_batch, p=2, dim=1)\n        pScore = cos_sim * w_c_norm\n        l1_norm = torch.norm(h, p=1, dim=1)\n        nci_score = pScore + alpha * l1_norm\n        \n        all_nci_scores.extend(nci_score.cpu().numpy())\n        all_true_labels.extend(y_true.numpy())\n\n    all_nci_scores = np.array(all_nci_scores)\n    all_true_labels = np.array(all_true_labels)\n    \n    id_mask = all_true_labels != OOD_LABEL\n    ood_mask = all_true_labels == OOD_LABEL\n    \n    id_scores_mean = all_nci_scores[id_mask].mean()\n    ood_scores_mean = all_nci_scores[ood_mask].mean()\n    \n    optimal_threshold = (id_scores_mean + ood_scores_mean) / 2.0\n    print(f\"\\nValidation ID Scores Mean: {id_scores_mean:.4f}\")\n    print(f\"Validation OOD Scores Mean: {ood_scores_mean:.4f}\")\n    print(f\"==> Optimal Threshold Found: {optimal_threshold:.4f}\")\n    \n    return optimal_threshold\n\n# Find the best threshold using ONLY the validation data\noptimal_threshold = find_optimal_threshold(model, feature_extractor, mu_G, w_c, val_loader, cfg.NCI_ALPHA)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T12:24:53.727088Z","iopub.execute_input":"2025-08-14T12:24:53.727488Z","iopub.status.idle":"2025-08-14T12:25:51.279026Z","shell.execute_reply.started":"2025-08-14T12:24:53.727461Z","shell.execute_reply":"2025-08-14T12:25:51.278202Z"}},"outputs":[{"name":"stdout","text":"\n--- Finding optimal threshold on validation set ---\n","output_type":"stream"},{"name":"stderr","text":"Analyzing validation scores: 100%|██████████| 90/90 [00:57<00:00,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"\nValidation ID Scores Mean: 1.6152\nValidation OOD Scores Mean: 1.1511\n==> Optimal Threshold Found: 1.3831\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# =================================================================\n# Cell 6: Final, Unbiased Evaluation on the TEST Set (Updated)\n# =================================================================\n@torch.no_grad()\ndef final_evaluation(model, feature_extractor, mu_G, w_c, test_loader, threshold, alpha):\n    print(\"\\n--- Final Evaluation on UNSEEN Test Set ---\")\n    model.eval()\n    feature_extractor.eval()\n\n    all_nci_scores, all_true_labels, all_initial_preds = [], [], []\n    OOD_LABEL = -1\n\n    for x, y_true in tqdm(test_loader, desc=\"Final evaluation\"):\n        x = x.to(cfg.DEVICE)\n        logits = model(x)\n        h = torch.flatten(feature_extractor(x), 1)\n        predicted_classes = torch.argmax(logits, dim=1)\n        h_centered = h - mu_G\n        w_c_batch = w_c[predicted_classes]\n\n        cos_sim = F.cosine_similarity(h_centered, w_c_batch)\n        w_c_norm = torch.norm(w_c_batch, p=2, dim=1)\n        pScore = cos_sim * w_c_norm\n        l1_norm = torch.norm(h, p=1, dim=1)\n        nci_score = pScore + alpha * l1_norm\n\n        all_nci_scores.extend(nci_score.cpu().numpy())\n        all_true_labels.extend(y_true.numpy())\n        all_initial_preds.extend(predicted_classes.cpu().numpy())\n\n    all_nci_scores = np.array(all_nci_scores)\n    all_true_labels = np.array(all_true_labels)\n    all_initial_preds = np.array(all_initial_preds)\n\n    # --- Create final predictions based on the threshold ---\n    final_preds = all_initial_preds.copy()\n    ood_mask_pred = all_nci_scores < threshold\n    final_preds[ood_mask_pred] = OOD_LABEL\n\n    # --- Masks for separating true ID and OOD samples ---\n    id_true_mask = all_true_labels != OOD_LABEL\n    ood_true_mask = all_true_labels == OOD_LABEL\n\n    # --- [NEW] Detailed Accuracy Calculation ---\n    print(\"\\n--- FINAL RESULTS ---\")\n\n    # 1. OOD Rejection Accuracy (same as before)\n    ood_accuracy = accuracy_score(all_true_labels[ood_true_mask], final_preds[ood_true_mask])\n    print(f\"1. Out-of-Distribution (OOD) Rejection Accuracy: {ood_accuracy:.2%}\")\n    print(\"   (How well the model rejects non-animals)\")\n\n    # 2. ID Detection Accuracy (New Metric)\n    # This checks how many true animals were correctly NOT labeled as OOD.\n    id_preds_for_detection = final_preds[id_true_mask]\n    # A correct prediction is anything that is NOT OOD (-1)\n    id_detection_accuracy = np.mean(id_preds_for_detection != OOD_LABEL)\n    print(f\"\\n2. In-Distribution (ID) Detection Accuracy: {id_detection_accuracy:.2%}\")\n    print(\"   (How well the model recognizes an animal is an animal)\")\n\n    # 3. ID Conditional Classification Accuracy (New Metric)\n    # First, get only the animals that were correctly detected as ID\n    correctly_detected_as_id_mask = (final_preds != OOD_LABEL) & (id_true_mask)\n    # Then, calculate classification accuracy on just this subset\n    conditional_class_accuracy = accuracy_score(\n        all_true_labels[correctly_detected_as_id_mask],\n        final_preds[correctly_detected_as_id_mask]\n    )\n    print(f\"\\n3. ID Conditional Classification Accuracy: {conditional_class_accuracy:.2%}\")\n    print(\"   (Of the animals it correctly identified as 'animal', how many did it classify correctly?)\")\n\n\n# --- Run the final evaluation using the optimal threshold found on the validation set ---\n# Make sure 'optimal_threshold' has been calculated from the previous cell\nfinal_evaluation(model, feature_extractor, mu_G, w_c, test_loader, optimal_threshold, cfg.NCI_ALPHA)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T12:25:59.551254Z","iopub.execute_input":"2025-08-14T12:25:59.551558Z","iopub.status.idle":"2025-08-14T12:28:11.304452Z","shell.execute_reply.started":"2025-08-14T12:25:59.551533Z","shell.execute_reply":"2025-08-14T12:28:11.303455Z"}},"outputs":[{"name":"stdout","text":"\n--- Final Evaluation on UNSEEN Test Set ---\n","output_type":"stream"},{"name":"stderr","text":"Final evaluation: 100%|██████████| 273/273 [02:11<00:00,  2.07it/s]","output_type":"stream"},{"name":"stdout","text":"\n--- FINAL RESULTS ---\n1. Out-of-Distribution (OOD) Rejection Accuracy: 95.16%\n   (How well the model rejects non-animals)\n\n2. In-Distribution (ID) Detection Accuracy: 92.18%\n   (How well the model recognizes an animal is an animal)\n\n3. ID Conditional Classification Accuracy: 92.21%\n   (Of the animals it correctly identified as 'animal', how many did it classify correctly?)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":10}]}